{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deployment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MY0OWRqpD5D",
        "colab_type": "text"
      },
      "source": [
        "# Deployment To Herkou\n",
        "# READ-3\n",
        "\n",
        "![Dir TREE](https://github.com/cd-x/plant-detect/tree.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPX-kY08r8D1",
        "colab_type": "text"
      },
      "source": [
        "this is our app.py\n",
        "\n",
        "here WSGIServer is the one which will keep our server running \n",
        "\n",
        "werkzeug utilities provides functionality for file uploading and storing it temporarily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxvLwJQwspqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import Flask, render_template, request,url_for,redirect,send_from_directory\n",
        "from werkzeug.utils import secure_filename\n",
        "from gevent.pywsgi import WSGIServer\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#part-prediction (moved from prediction.py)\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import itertools\n",
        "import random\n",
        "from collections import Counter\n",
        "from glob import iglob\n",
        "import uuid\n",
        "import base64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCqQTzj7sy5w",
        "colab_type": "text"
      },
      "source": [
        "Loading our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdaynKnAs2_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "MODEL_PATH = './model/acc9275own.h5'\n",
        "\n",
        "model=load_model(MODEL_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIk_mY7Es9kK",
        "colab_type": "text"
      },
      "source": [
        "getting 38 classes in a list so that we can retrive it from index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0d_svitJyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('categories.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)\n",
        "    classes = list(cat_to_name.values())\n",
        "    \n",
        "#print (classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_N7mm3JtTIi",
        "colab_type": "text"
      },
      "source": [
        "loading and predicting we've talked in READ-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUIsrH4rtbuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "IMAGE_SIZE=(224,224)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_image(filename):\n",
        "    img = cv2.imread(filename)\n",
        "    #img = cv2.imread(os.path.join(image_dir, filename)) #<-- use in case of test through existing validation dataset\n",
        "    img = cv2.resize(img, (IMAGE_SIZE[0], IMAGE_SIZE[1]) )\n",
        "    img = img /255\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    probabilities = model.predict(np.asarray([image]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "    \n",
        "    return {classes[class_idx]: probabilities[class_idx]}\n",
        "\n",
        "\n",
        "# def say_hello():\n",
        "#     print('function added')\n",
        "#     print(classes)\n",
        "#     print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WETmzF79th3Y",
        "colab_type": "text"
      },
      "source": [
        "my_random_sring just encrypts the given filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ4q5mUJtse6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#part-predicction\n",
        "def get_as_base64(url):\n",
        "    return base64.b64encode(requests.get(url).content)\n",
        "\n",
        "def my_random_string(string_length=10):\n",
        "    \"\"\"Returns a random string of length string_length.\"\"\"\n",
        "    random = str(uuid.uuid4()) # Convert UUID format to a Python string.\n",
        "    random = random.upper() # Make all characters uppercase.\n",
        "    random = random.replace(\"-\",\"\") # Remove the UUID '-'.\n",
        "    return random[0:string_length] # Return the random string.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lms0H5dOt41m",
        "colab_type": "text"
      },
      "source": [
        "Routing API request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_fagDbAtwOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "root_dir = os.path.dirname(__file__)\n",
        "\n",
        "ALLOWED_EXTENSIONS = set(['jpg', 'jpeg', 'png'])\n",
        "app.config['UPLOAD_FOLDER']='uploads'\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1] in ALLOWED_EXTENSIONS\n",
        "\n",
        "\n",
        "@app.route(\"/\",methods=['GET'])\n",
        "def index():\n",
        "\treturn render_template('base.html',label='',imagesource='../uploads/example.jpg')\n",
        "\n",
        "\n",
        "@app.route('/',methods=['GET','POST'])\n",
        "def upload():\n",
        "\tif request.method == 'POST':\n",
        "\t\tfile = request.files['file']\n",
        "\t\t#saving file to uploads directory\n",
        "\t\tresult='please upload a file'\n",
        "\t\tif file and allowed_file(file.filename):\n",
        "\n",
        "\t\t\tfilename=secure_filename(file.filename)\n",
        "\t\t\tfile_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "\t\t\tfile.save(file_path)\n",
        "\n",
        "\t\t\t#prediction part\n",
        "\t\t\timg = load_image(file_path)\n",
        "\t\t\tresult = predict(img)\n",
        "\t\t\tfilename= my_random_string(6) + filename\n",
        "\t\t\tos.rename(file_path, os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "\treturn render_template('base.html',imagesource='../uploads/'+filename,label=result)\n",
        "\n",
        "\n",
        "#upload API\n",
        "@app.route('/uploads/<filename>')\n",
        "def uploaded_file(filename):\n",
        "    return send_from_directory(app.config['UPLOAD_FOLDER'],\n",
        "                               filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdgUE82duATh",
        "colab_type": "text"
      },
      "source": [
        "**This part is more important since heroku doesn't provide any image storing memory it just gives ram so to process the image we need to store the image somewhere below code does it very cleverly it srores the data temporarily in the ram and as soon as its done it removes the file from memory**\n",
        "\n",
        "```\n",
        "from werkzeug.middleware.shared_data import SharedDataMiddleware\n",
        "```\n",
        "Making SharedDataMiddleWare's build_only parameter True will do the same "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IipH1xjno8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from werkzeug.middleware.shared_data import SharedDataMiddleware\n",
        "app.add_url_rule('/uploads/<filename>', 'uploaded_file',\n",
        "                 build_only=True)\n",
        "app.wsgi_app = SharedDataMiddleware(app.wsgi_app, {\n",
        "    '/uploads':  app.config['UPLOAD_FOLDER']\n",
        "})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tapp.run(debug=False, threaded=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-LeNQJBvTUK",
        "colab_type": "text"
      },
      "source": [
        "# heroku deployment process\n",
        "\n",
        "\n",
        "\n",
        "1.   If project works fine on localhost make Debug=False\n",
        "\n",
        "2.   $pip freeze > requirements.txt\n",
        "\n",
        "2.   $git init\n",
        "\n",
        "3.   $git add .\n",
        "\n",
        "4.   $git commit -m \"deploying\"\n",
        "\n",
        "5.   $git remote add origin [ git-repo-url ]\n",
        "\n",
        "6.   $git push -u origin master\n",
        "\n",
        "8.   create new app on heroku \n",
        "\n",
        "9.   connect with your repo using option connect with github\n",
        "\n",
        "10.  $git push heroku master\n",
        "\n",
        "**Few important commands**\n",
        "\n",
        "$heroku logs --tail --app [app-name]\n",
        "\n",
        "In case of memory quota exceeded ERROR\n",
        "\n",
        "set WEB_CONCURRENCY TO 1 OR 2\n",
        "\n",
        "In case if you want to make any changes to your running project \n",
        "\n",
        "1.   add change locally to your git repository \n",
        "\n",
        "2.  perform git staging\n",
        "\n",
        "3.  run command '10' mentioned above heroku itself will look for change if there is any in requirements.txt it will reinstall ooonly that item or if there is only change in code it will just change that code and will start re-building. It takes just few seconds once done voila !! you have your new version of the app.\n",
        "\n",
        "**!! Stay alert if slug size is more than 500 mb your app will crash !!**\n",
        "\n"
      ]
    }
  ]
}